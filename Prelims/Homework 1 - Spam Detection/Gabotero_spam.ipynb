{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c247efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                               text\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "data = pd.read_csv('spam.csv',encoding='latin-1')\n",
    "\n",
    "data = data.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "data = data.rename(columns={\"v1\":'label', \"v2\":'text'})\n",
    "print(data.head())\n",
    "tags = data[\"label\"]\n",
    "texts = data[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4130e73e",
   "metadata": {},
   "source": [
    "## To do: develop an accurate simple neural network model for spam classification (no LSTM, CNN, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2ff2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04646c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'text'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2386d2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ham  spam\n",
       "0       1     0\n",
       "1       1     0\n",
       "2       0     1\n",
       "3       1     0\n",
       "4       1     0\n",
       "...   ...   ...\n",
       "5567    0     1\n",
       "5568    1     0\n",
       "5569    1     0\n",
       "5570    1     0\n",
       "5571    1     0\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=pd.get_dummies(data['label'],drop_first=False)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29545ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = data['text'].tolist()\n",
    "labels = data2['spam'].tolist()\n",
    "\n",
    "training_size = int(len(sentences) * 0.8)\n",
    "\n",
    "training_sentences = sentences[0:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]\n",
    "\n",
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae41432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 600, oov_token = \"<OOV>\")\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences, maxlen = 60, padding = 'post', truncating = 'post')\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen = 60, padding = 'post', truncating = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbdc5d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 60, 16)            9600      \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 102       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,709\n",
      "Trainable params: 9,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(600, 16, input_length = 60),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63720dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "140/140 [==============================] - 3s 8ms/step - loss: 0.5624 - accuracy: 0.8647 - val_loss: 0.3965 - val_accuracy: 0.8700\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3487 - accuracy: 0.8649 - val_loss: 0.3048 - val_accuracy: 0.8700\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.2802 - accuracy: 0.8652 - val_loss: 0.2290 - val_accuracy: 0.8717\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.2027 - accuracy: 0.9028 - val_loss: 0.1611 - val_accuracy: 0.9534\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.1488 - accuracy: 0.9545 - val_loss: 0.1209 - val_accuracy: 0.9668\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.1108 - accuracy: 0.9684 - val_loss: 0.0919 - val_accuracy: 0.9749\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0859 - accuracy: 0.9744 - val_loss: 0.0722 - val_accuracy: 0.9776\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0694 - accuracy: 0.9794 - val_loss: 0.0627 - val_accuracy: 0.9794\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0602 - accuracy: 0.9818 - val_loss: 0.0565 - val_accuracy: 0.9794\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0537 - accuracy: 0.9843 - val_loss: 0.0534 - val_accuracy: 0.9821\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0487 - accuracy: 0.9859 - val_loss: 0.0500 - val_accuracy: 0.9812\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9863 - val_loss: 0.0499 - val_accuracy: 0.9839\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0422 - accuracy: 0.9877 - val_loss: 0.0477 - val_accuracy: 0.9830\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0392 - accuracy: 0.9890 - val_loss: 0.0473 - val_accuracy: 0.9839\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9892 - val_loss: 0.0459 - val_accuracy: 0.9839\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0342 - accuracy: 0.9897 - val_loss: 0.0458 - val_accuracy: 0.9839\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0325 - accuracy: 0.9901 - val_loss: 0.0449 - val_accuracy: 0.9857\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9908 - val_loss: 0.0449 - val_accuracy: 0.9857\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0285 - accuracy: 0.9917 - val_loss: 0.0464 - val_accuracy: 0.9848\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.0448 - val_accuracy: 0.9848\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 0.0448 - val_accuracy: 0.9857\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.0451 - val_accuracy: 0.9857\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0455 - val_accuracy: 0.9839\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9930 - val_loss: 0.0456 - val_accuracy: 0.9865\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 0.0463 - val_accuracy: 0.9874\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0210 - accuracy: 0.9928 - val_loss: 0.0479 - val_accuracy: 0.9821\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0470 - val_accuracy: 0.9874\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.0475 - val_accuracy: 0.9848\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0485 - val_accuracy: 0.9839\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.0484 - val_accuracy: 0.9839\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.0511 - val_accuracy: 0.9830\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.0498 - val_accuracy: 0.9848\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.0506 - val_accuracy: 0.9848\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.0518 - val_accuracy: 0.9857\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.0527 - val_accuracy: 0.9839\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.0573 - val_accuracy: 0.9812\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.0542 - val_accuracy: 0.9857\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.0551 - val_accuracy: 0.9857\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.0561 - val_accuracy: 0.9830\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0574 - val_accuracy: 0.9830\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.0574 - val_accuracy: 0.9839\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.0583 - val_accuracy: 0.9839\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.0595 - val_accuracy: 0.9839\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0611 - val_accuracy: 0.9857\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.0618 - val_accuracy: 0.9848\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0627 - val_accuracy: 0.9848\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9978 - val_loss: 0.0635 - val_accuracy: 0.9839\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 0.0649 - val_accuracy: 0.9848\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.0664 - val_accuracy: 0.9839\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0670 - val_accuracy: 0.9839\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.0689 - val_accuracy: 0.9830\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0704 - val_accuracy: 0.9848\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.9984 - val_loss: 0.0705 - val_accuracy: 0.9839\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.0723 - val_accuracy: 0.9830\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.0738 - val_accuracy: 0.9821\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.0738 - val_accuracy: 0.9830\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.0753 - val_accuracy: 0.9830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.0757 - val_accuracy: 0.9839\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 1s 8ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.0773 - val_accuracy: 0.9830\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.0780 - val_accuracy: 0.9830\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0805 - val_accuracy: 0.9821\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0811 - val_accuracy: 0.9830\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.0815 - val_accuracy: 0.9830\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0829 - val_accuracy: 0.9839\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 1s 7ms/step - loss: 0.0067 - accuracy: 0.9989 - val_loss: 0.0839 - val_accuracy: 0.9830\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0857 - val_accuracy: 0.9821\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.0864 - val_accuracy: 0.9830\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0875 - val_accuracy: 0.9830\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.0886 - val_accuracy: 0.9839\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0898 - val_accuracy: 0.9830\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.0915 - val_accuracy: 0.9839\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0918 - val_accuracy: 0.9830\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0929 - val_accuracy: 0.9830\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0945 - val_accuracy: 0.9830\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0947 - val_accuracy: 0.9839\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0959 - val_accuracy: 0.9839\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.0979 - val_accuracy: 0.9839\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.0988 - val_accuracy: 0.9839\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.0997 - val_accuracy: 0.9839\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.1020 - val_accuracy: 0.9830\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.1038 - val_accuracy: 0.9839\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.1041 - val_accuracy: 0.9830\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.1047 - val_accuracy: 0.9839\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.1058 - val_accuracy: 0.9839\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1067 - val_accuracy: 0.9821\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.1073 - val_accuracy: 0.9830\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.1080 - val_accuracy: 0.9830\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.1097 - val_accuracy: 0.9848\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.1099 - val_accuracy: 0.9839\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.1111 - val_accuracy: 0.9839\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.1137 - val_accuracy: 0.9839\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.1150 - val_accuracy: 0.9830\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.1150 - val_accuracy: 0.9839\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1169 - val_accuracy: 0.9830\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.1210 - val_accuracy: 0.9785\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1209 - val_accuracy: 0.9812\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1224 - val_accuracy: 0.9812\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.1218 - val_accuracy: 0.9821\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1253 - val_accuracy: 0.9785\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1267 - val_accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "history=model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e41a9d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1267 - accuracy: 0.9803\n",
      "[+] Accuracy: 98.03%\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(testing_padded, testing_labels_final)\n",
    "\n",
    "loss = result[0]\n",
    "accuracy = result[1]\n",
    "\n",
    "print(f\"[+] Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a37755ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Feel Yourself That You Are Always Happy.. Slow...\n",
      "1     staff.science.nus.edu.sg/~phyhcmk/teaching/pc1323\n",
      "2                           Send me yetty's number pls.\n",
      "3     Hey so this sat are we going for the intro pil...\n",
      "4     I got it before the new year cos yetunde said ...\n",
      "5     Hey we can go jazz power yoga hip hop kb and y...\n",
      "6     Hey mate. Spoke to the mag people. WeÃ¢Â€Â°ÃƒÂ›ÃƒÂ·re...\n",
      "7                                Morning only i can ok.\n",
      "8                                  Wat time ÃƒÂŒ_ finish?\n",
      "9                 Shant disturb u anymore... Jia you...\n",
      "10    4mths half price Orange line rental & latest c...\n",
      "11    Your opinion about me? 1. Over 2. Jada 3. Kusr...\n",
      "12    MOON has come to color your dreams, STARS to m...\n",
      "13    You are a winner U have been specially selecte...\n",
      "14    Unless it's a situation where YOU GO GURL woul...\n",
      "15    Awww dat is sweet! We can think of something t...\n",
      "16                              Bring tat cd don forget\n",
      "17    Single line with a big meaning::::: \\Miss anyt...\n",
      "18       Jay's getting really impatient and belligerent\n",
      "19    Lol they were mad at first but then they woke ...\n",
      "Name: text, dtype: object\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "Feel Yourself That You Are Always Happy.. Slowly It Becomes Your Habit &amp; Finally It Becomes Part Of Your Life.. Follow It.. Happy Morning &amp; Have A Happy Day:)\n",
      "[1.2293133e-14]\n",
      "\n",
      "\n",
      "staff.science.nus.edu.sg/~phyhcmk/teaching/pc1323\n",
      "[0.03104385]\n",
      "\n",
      "\n",
      "Send me yetty's number pls.\n",
      "[0.0003569]\n",
      "\n",
      "\n",
      "Hey so this sat are we going for the intro pilates only? Or the kickboxing too? \n",
      "[6.945466e-08]\n",
      "\n",
      "\n",
      "I got it before the new year cos yetunde said she wanted to surprise you with it but when i didnt see money i returned it mid january before the  &lt;#&gt; day return period ended.\n",
      "[3.9615244e-15]\n",
      "\n",
      "\n",
      "Hey we can go jazz power yoga hip hop kb and yogasana \n",
      "[2.2135568e-05]\n",
      "\n",
      "\n",
      "Hey mate. Spoke to the mag people. WeÃ¢Â€Â°ÃƒÂ›ÃƒÂ·re on.  the is deliver by the end of the month. Deliver on the 24th sept. Talk later. \n",
      "[1.2570717e-06]\n",
      "\n",
      "\n",
      "Morning only i can ok.\n",
      "[7.954439e-08]\n",
      "\n",
      "\n",
      "Wat time ÃƒÂŒ_ finish?\n",
      "[2.5183674e-06]\n",
      "\n",
      "\n",
      "Shant disturb u anymore... Jia you...\n",
      "[0.01992686]\n",
      "\n",
      "\n",
      "4mths half price Orange line rental & latest camera phones 4 FREE. Had your phone 11mths ? Call MobilesDirect free on 08000938767 to update now! or2stoptxt\n",
      "[0.999999]\n",
      "\n",
      "\n",
      "Your opinion about me? 1. Over 2. Jada 3. Kusruthi 4. Lovable 5. Silent 6. Spl character 7. Not matured 8. Stylish 9. Simple Pls reply..\n",
      "[0.0001212]\n",
      "\n",
      "\n",
      "MOON has come to color your dreams, STARS to make them musical and my SMS to give you warm and Peaceful Sleep. Good Night\n",
      "[0.00052711]\n",
      "\n",
      "\n",
      "You are a winner U have been specially selected 2 receive ÃƒÂ¥Ã‚Â£1000 cash or a 4* holiday (flights inc) speak to a live operator 2 claim 0871277810810\n",
      "[0.999988]\n",
      "\n",
      "\n",
      "Unless it's a situation where YOU GO GURL would be more appropriate\n",
      "[7.177125e-06]\n",
      "\n",
      "\n",
      "Awww dat is sweet! We can think of something to do he he! Have a nice time tonight ill probably txt u later cos im lonely :( xxx.\n",
      "[1.0522889e-12]\n",
      "\n",
      "\n",
      "Bring tat cd don forget\n",
      "[3.3745913e-05]\n",
      "\n",
      "\n",
      "Single line with a big meaning::::: \\Miss anything 4 ur \\\"Best Life\\\" but\n",
      "[4.717387e-06]\n",
      "\n",
      "\n",
      "Jay's getting really impatient and belligerent\n",
      "[0.00291862]\n",
      "\n",
      "\n",
      "Lol they were mad at first but then they woke up and gave in.\n",
      "[5.0835433e-06]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data3 = pd.read_csv('output_spam.csv',encoding='latin-1')\n",
    "text_messages = data3['text']\n",
    "\n",
    "print(text_messages) \n",
    "\n",
    "padding_type='post'\n",
    "sample_sequences = tokenizer.texts_to_sequences(text_messages)\n",
    "fakes_padded = pad_sequences(sample_sequences, padding = 'post', maxlen = 60)           \n",
    "\n",
    "classes = model.predict(fakes_padded)\n",
    "\n",
    "for x in range(len(text_messages)):\n",
    "  print(text_messages[x])\n",
    "  print(classes[x])\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e7e07c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spamham = ['spam' if x > 0.1 else 'ham' for x in classes]\n",
    "outputcsv = pd.DataFrame(spamham, columns = ['label']).to_csv('output_spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cd43f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = pd.read_csv('output_spam.csv')\n",
    "data4[\"text\"] = text_messages\n",
    "data4.to_csv('output_spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77cb520e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Feel Yourself That You Are Always Happy.. Slow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>staff.science.nus.edu.sg/~phyhcmk/teaching/pc1323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Send me yetty's number pls.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey so this sat are we going for the intro pil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I got it before the new year cos yetunde said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey we can go jazz power yoga hip hop kb and y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey mate. Spoke to the mag people. WeÃ¢Â€Â°ÃƒÂ›ÃƒÂ·re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>Morning only i can ok.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wat time ÃƒÂŒ_ finish?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ham</td>\n",
       "      <td>Shant disturb u anymore... Jia you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spam</td>\n",
       "      <td>4mths half price Orange line rental &amp; latest c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ham</td>\n",
       "      <td>Your opinion about me? 1. Over 2. Jada 3. Kusr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ham</td>\n",
       "      <td>MOON has come to color your dreams, STARS to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spam</td>\n",
       "      <td>You are a winner U have been specially selecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>Unless it's a situation where YOU GO GURL woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ham</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Bring tat cd don forget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Single line with a big meaning::::: \\Miss anyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Jay's getting really impatient and belligerent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol they were mad at first but then they woke ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0    ham  Feel Yourself That You Are Always Happy.. Slow...\n",
       "1    ham  staff.science.nus.edu.sg/~phyhcmk/teaching/pc1323\n",
       "2    ham                        Send me yetty's number pls.\n",
       "3    ham  Hey so this sat are we going for the intro pil...\n",
       "4    ham  I got it before the new year cos yetunde said ...\n",
       "5    ham  Hey we can go jazz power yoga hip hop kb and y...\n",
       "6    ham  Hey mate. Spoke to the mag people. WeÃ¢Â€Â°ÃƒÂ›ÃƒÂ·re...\n",
       "7    ham                             Morning only i can ok.\n",
       "8    ham                               Wat time ÃƒÂŒ_ finish?\n",
       "9    ham              Shant disturb u anymore... Jia you...\n",
       "10  spam  4mths half price Orange line rental & latest c...\n",
       "11   ham  Your opinion about me? 1. Over 2. Jada 3. Kusr...\n",
       "12   ham  MOON has come to color your dreams, STARS to m...\n",
       "13  spam  You are a winner U have been specially selecte...\n",
       "14   ham  Unless it's a situation where YOU GO GURL woul...\n",
       "15   ham  Awww dat is sweet! We can think of something t...\n",
       "16   ham                            Bring tat cd don forget\n",
       "17   ham  Single line with a big meaning::::: \\Miss anyt...\n",
       "18   ham     Jay's getting really impatient and belligerent\n",
       "19   ham  Lol they were mad at first but then they woke ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5 = pd.read_csv('output_spam.csv')\n",
    "cols=data5.columns\n",
    "cols=['label','text']\n",
    "data5=data5[cols]\n",
    "data5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfa23865",
   "metadata": {},
   "outputs": [],
   "source": [
    "data5.to_csv('output_spam.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
